{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4-Xc_YBykNP",
        "outputId": "10ee41f4-f396-4467-d8d8-1a57b9890e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/MyDrive/Colab Notebooks/diabetes.csv'"
      ],
      "metadata": {
        "id": "Zw-gUErA4Xz2"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n",
        "                                     initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXw4pl0X4fhg",
        "outputId": "36a8fe68-2df4-41dd-a10f-07536a915e87"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 2ms/step - loss: 30.2670 - acc: 0.3993\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 18.6599 - acc: 0.4583\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 11.5502 - acc: 0.5434\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 7.3486 - acc: 0.6250\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 5.4821 - acc: 0.6458\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 3.8151 - acc: 0.6146\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 3.1318 - acc: 0.5833\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 2.9191 - acc: 0.5729\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 2.7294 - acc: 0.5972\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 2.5402 - acc: 0.5938\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 2.3694 - acc: 0.6146\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 2.2041 - acc: 0.6094\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 2.0420 - acc: 0.6163\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 1.8969 - acc: 0.6285\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 1.7743 - acc: 0.6233\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 1.6335 - acc: 0.6458\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 1.5121 - acc: 0.6337\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 1.4007 - acc: 0.6458\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 1.3314 - acc: 0.6493\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.1976 - acc: 0.6649\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.1253 - acc: 0.6649\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0734 - acc: 0.6649\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9602 - acc: 0.6771\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8960 - acc: 0.6667\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8559 - acc: 0.6788\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7966 - acc: 0.6701\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7834 - acc: 0.6788\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.7496 - acc: 0.6910\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7191 - acc: 0.6962\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.6901 - acc: 0.6823\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6847 - acc: 0.6910\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6819 - acc: 0.6927\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6505 - acc: 0.6910\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6621 - acc: 0.6979\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6586 - acc: 0.6719\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6238 - acc: 0.7118\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6200 - acc: 0.7118\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6193 - acc: 0.7101\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6244 - acc: 0.6927\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6063 - acc: 0.7188\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6075 - acc: 0.7118\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.6667 - acc: 0.6858\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6704 - acc: 0.6840\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6908 - acc: 0.6736\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5948 - acc: 0.7049\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6200 - acc: 0.6997\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6007 - acc: 0.6840\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5777 - acc: 0.7257\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5955 - acc: 0.7170\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6126 - acc: 0.7014\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6068 - acc: 0.7014\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5884 - acc: 0.7326\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5817 - acc: 0.7118\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6526 - acc: 0.6823\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5876 - acc: 0.7031\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5670 - acc: 0.7344\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5681 - acc: 0.7205\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5826 - acc: 0.7240\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5659 - acc: 0.7205\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5669 - acc: 0.7205\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5758 - acc: 0.7049\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5564 - acc: 0.7344\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5909 - acc: 0.7066\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6017 - acc: 0.7083\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6478 - acc: 0.6927\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5569 - acc: 0.7205\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5659 - acc: 0.7170\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5581 - acc: 0.7188\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5518 - acc: 0.7483\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5473 - acc: 0.7292\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5694 - acc: 0.7188\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5735 - acc: 0.7101\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5599 - acc: 0.7135\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6241 - acc: 0.6823\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5641 - acc: 0.7361\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5555 - acc: 0.7240\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5459 - acc: 0.7344\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5424 - acc: 0.7344\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5433 - acc: 0.7378\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5430 - acc: 0.7326\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5580 - acc: 0.7378\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5429 - acc: 0.7257\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5556 - acc: 0.7240\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5405 - acc: 0.7257\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5479 - acc: 0.7309\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5351 - acc: 0.7465\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5332 - acc: 0.7240\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5438 - acc: 0.7552\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5389 - acc: 0.7344\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5433 - acc: 0.7101\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5574 - acc: 0.7257\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5516 - acc: 0.7309\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5468 - acc: 0.7396\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5344 - acc: 0.7378\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5423 - acc: 0.7396\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5674 - acc: 0.7292\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5929 - acc: 0.7153\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5657 - acc: 0.7188\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5444 - acc: 0.7378\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5393 - acc: 0.7361\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_79 (Dense)            (None, 20)                180       \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201\n",
            "Trainable params: 201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6006 - acc: 0.7135\n",
            "[0.6005604863166809, 0.7135416865348816]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "SYWWGlY-4dpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load dataset\n",
        "path_to_csv = '/content/gdrive/MyDrive/Colab Notebooks/diabetes.csv'\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "# split dataset into training and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "\n",
        "# define the model\n",
        "np.random.seed(155)\n",
        "my_second_nn = Sequential()\n",
        "my_second_nn.add(Dense(20, input_dim=8, activation='relu'))\n",
        "my_second_nn.add(Dense(20, input_dim=8,activation='relu'))\n",
        "my_second_nn.add(Dense(20, input_dim=8,activation='relu'))\n",
        "my_second_nn.add(Dense(1, activation='sigmoid'))\n",
        "my_second_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "my_second_nn_fitted= my_second_nn.fit(X_train, Y_train, epochs=100,\n",
        "                                     initial_epoch=0)\n",
        "\n",
        "\n",
        "# evaluate the model on the test set\n",
        "score = my_second_nn.evaluate(X_test, Y_test, batch_size=64)\n",
        "print(my_second_nn.summary())\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91rowao1ma2j",
        "outputId": "c4ea3549-689a-4b92-d918-72ca95b63602"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 2ms/step - loss: 14.1514 - accuracy: 0.6615\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 4.4818 - accuracy: 0.5208\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 1.7223 - accuracy: 0.5851\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0627 - accuracy: 0.6163\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.7551 - accuracy: 0.6493\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.6597\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6510\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6580\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6753\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6788\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6632\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6858\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6649\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7083\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6892\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.6858\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7049\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6615\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7014\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7135\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7135\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7031\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7101\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7292\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7292\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7222\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7135\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7274\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7188\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7135\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7292\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.6944\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7049\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7101\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7274\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7135\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7135\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7257\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7465\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7344\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7292\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7344\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7413\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7465\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7361\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7396\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7361\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7413\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7483\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7188\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7326\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7413\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7465\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7552\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7309\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7639\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7257\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7483\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7222\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7222\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7483\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.5282 - accuracy: 0.7396\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7378\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7361\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7465\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7517\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7483\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7448\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7378\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7622\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7431\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7517\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7448\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7708\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7517\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7656\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7448\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7517\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7344\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7865\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7639\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7535\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7344\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7778\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7743\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7622\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7708\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7760\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7674\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7622\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7656\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7743\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7743\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7674\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7778\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.6927\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_81 (Dense)            (None, 20)                180       \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,041\n",
            "Trainable params: 1,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Test accuracy: 0.6927083134651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/MyDrive/Colab Notebooks/breastcancer.csv'"
      ],
      "metadata": {
        "id": "cb1SktEvolYY"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target,\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "\n",
        "# Normalize data\n",
        "sc = StandardScaler()\n",
        "X_train_norm = sc.fit_transform(X_train)\n",
        "X_test_norm = sc.transform(X_test)\n",
        "\n",
        "# Create model\n",
        "np.random.seed(155)\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=30, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train_norm, y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "# Evaluate model on testing set\n",
        "loss, accuracy = model.evaluate(X_test_norm, y_test)\n",
        "print(model.summary())\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taaEW4BO2w5t",
        "outputId": "33245c32-297d-4128-a6be-70c39c139b09"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 0.9206 - accuracy: 0.4836\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.6221\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7676\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8615\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.9061\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9249\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9390\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9437\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9484\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9507\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9554\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9577\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9577\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9601\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.9601\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9624\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9648\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9648\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9671\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9671\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9695\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9695\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9695\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9695\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0782 - accuracy: 0.9695\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9718\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9742\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9765\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9765\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9789\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9789\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9812\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9812\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9812\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9812\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9812\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9812\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9836\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9836\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9836\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9812\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9836\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9812\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9812\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9812\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9812\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9812\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9812\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9812\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9812\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9812\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9812\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9836\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9859\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9859\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9859\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9859\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9859\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9883\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9883\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9883\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9883\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9883\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9883\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9883\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9883\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9883\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9883\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9883\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9883\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9883\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9906\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9906\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9906\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9906\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9906\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9906\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9930\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9930\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9930\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9930\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9930\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9930\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9930\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9930\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9930\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9930\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9930\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9930\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9930\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9930\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9930\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9930\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9930\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9930\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9930\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9930\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9930\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9930\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9930\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9650\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_85 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 641\n",
            "Trainable params: 641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Loss: 0.1371341347694397\n",
            "Accuracy: 0.9650349617004395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BMuK0ax8pECE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}